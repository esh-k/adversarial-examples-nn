{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e197374",
   "metadata": {},
   "source": [
    "# Fooling a NN (Advasarial examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325bb7f0",
   "metadata": {},
   "source": [
    "Here, I'm trying to create an advasarial example using gradient descent with some of the ideas coming from [Attacking Machine Learning\n",
    "with Adversarial Examples](https://openai.com/blog/adversarial-example-research/). The inception v3 model trained on imagenet.\n",
    "\n",
    "Essentially, this is what I do:\n",
    "- Choose a test image and verify that the the model can classify it.\n",
    "- Choose an advasarial class and perform gradient descent on the test image.\n",
    "- Verify that the model has been fooled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4e62d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import tensorflow_hub as hub\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import json\n",
    "\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249bc813",
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_model = tf.keras.applications.InceptionV3()\n",
    "inception_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc727de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor_shape = inception_model.layers[0].input_shape\n",
    "image_height = input_tensor_shape[0][1]\n",
    "image_width = input_tensor_shape[0][2]\n",
    "image_shape = (image_height, image_width)\n",
    "print(f\"input image shape (height, width) = {image_shape}\")\n",
    "\n",
    "output_tensor_shape = inception_model.layers[-1].output_shape\n",
    "n_classes = output_tensor_shape[1]\n",
    "print(f\"number of classes = {n_classes}\")\n",
    "\n",
    "with open('imagenet_class_names.txt', 'r') as f:\n",
    "    class_names = eval(f.read())\n",
    "\n",
    "assert(n_classes == len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a207a3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_from_path(img_path, target_size):\n",
    "    img = image.load_img(img_path, target_size=target_size)\n",
    "    img_tensor = image.img_to_array(img)\n",
    "    img_tensor = np.expand_dims(img_tensor, axis=0) / 255.\n",
    "    return (img, img_tensor)\n",
    "\n",
    "def get_prediction(tensor, class_names):\n",
    "    pred = inception_model.predict(tensor)\n",
    "    assert(pred.shape == (1,len(class_names)))\n",
    "    pred_class = tf.math.argmax(pred[0]).numpy()\n",
    "    return class_names[pred_class], pred[0, pred_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dca6a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img, test_img_tensor = load_image_from_path('./test_images/test_dog.jpg', target_size=(image_height, image_width))\n",
    "print(f'Input image shape: {test_img_tensor.shape}')\n",
    "imshow(test_img)\n",
    "plt.show()\n",
    "\n",
    "class_name, confidence = get_prediction(test_img_tensor, class_names)\n",
    "print(f\"'{class_name}' with confidence {confidence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da880a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_image(tensor):\n",
    "    \"\"\" Converts image tensor to PIL.Image\"\"\"\n",
    "    \n",
    "    tensor = tensor * 255\n",
    "    tensor = np.array(tensor, dtype=np.uint8)\n",
    "    if np.ndim(tensor) > 3:\n",
    "        assert tensor.shape[0] == 1\n",
    "        tensor = tensor[0]\n",
    "    return PIL.Image.fromarray(tensor)\n",
    "\n",
    "def create_label_for_class(class_index, n_classes):\n",
    "    \"\"\" Create a one hot encoded label for the class_index\"\"\"\n",
    "    \n",
    "    hack_labels = np.zeros((1,n_classes), dtype=np.float32)\n",
    "    hack_labels[0, class_index] = 1\n",
    "    hack_labels = tf.convert_to_tensor(hack_labels)\n",
    "    return hack_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3129e45a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.03)\n",
    "\n",
    "@tf.function()\n",
    "def train_step(img, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = inception_model(img)\n",
    "        cost = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "    grad = tape.gradient(cost, img)\n",
    "    optimizer.apply_gradients([(grad, img)])\n",
    "    img.assign(tf.clip_by_value(img, clip_value_min=0.0, clip_value_max=1.0))\n",
    "    return cost\n",
    "\n",
    "img_tensor = tf.Variable(tf.identity(test_img_tensor))\n",
    "epochs = 1001\n",
    "hack_labels = create_label_for_class(23, n_classes) # vulture\n",
    "j1 = train_step(img_tensor, hack_labels)\n",
    "print(j1)\n",
    "j2 = train_step(img_tensor, hack_labels)\n",
    "print(j2)\n",
    "\n",
    "# print(tf.compat.v1.trainable_variables())\n",
    "for i in range(1, epochs):\n",
    "    train_step(img_tensor, hack_labels)\n",
    "    if i %250 == 0:\n",
    "        print(f\"Epoch {i}\")\n",
    "        img = tensor_to_image(img_tensor)\n",
    "        imshow(img)\n",
    "        plt.show()\n",
    "        name, confidence = get_prediction(tf.convert_to_tensor(img_tensor), class_names)\n",
    "        print(f\"Prediction: '{name}', confidence={confidence}\")\n",
    "\n",
    "img.save('./test_images/trained_image.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8398e3",
   "metadata": {},
   "source": [
    "As you can see the model is predicting the image is a 'vulture'. \n",
    "\n",
    "This doesn't work well once the image is saved, I suspect that the compression removes someof te details so the initial effect should be prominent for this to work. The opposite can be checked for a lower value of alpha (learning rate) in the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3280bf29",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_img2, test_img2_tensor = load_image_from_path('./test_images/trained_image.jpg', target_size=image_shape)\n",
    "print(get_prediction(test_img2_tensor, class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f291a8",
   "metadata": {},
   "source": [
    "Other references\n",
    "- [\"Explaining and Harnessing Adversarial Examples\", Ian J. Goodfellow, Jonathon Shlens, Christian Szegedy](https://arxiv.org/abs/1412.6572)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
